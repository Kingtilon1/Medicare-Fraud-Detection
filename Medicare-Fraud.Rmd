title: "Medicare Fraud"
output: html_document
date: "2024-09-17"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(httr)
library(jsonlite)
library(sparklyr)
library(tidycensus)
library(dplyr)
library(purrr)
library(DBI)
library(knitr)
library(RMySQL)
library(data.table)
library(caret)
library(pROC)
library(ROSE)  
library(ggplot2)
options(rstudio.connectionObserver.errorsSuppressed = TRUE)
```

The Data was too big to upload directly to R, so it was uploaded to mysql Workbench instead for aggregation before being pulled back into R

```{r}
con <- dbConnect(RMySQL::MySQL(), 

                 dbname = "fraud", 

                 host = "localhost", 

                 port = 3306, 

                 user = "root", 

                 password = "Kidace909")

dbSendQuery(con, "SET GLOBAL local_infile = true;") # <--- Added this

```




```{r}
# Open the file connection
cons <- file("C:\\Users\\bobbt\\Downloads\\Medicare_Part_D_Prescribers_by_Provider_and_Drug_2022.csv", open = "r")

# Count total lines in the file (each line corresponds to a row)
total_rows <- 0
while (length(line <- readLines(cons, n = 1, warn = FALSE)) > 0) {
  total_rows <- total_rows + 1
}
close(cons)

# Print total number of rows (including the header)
total_rows
```


```{r}
# Define the split point (half of the file)
split_point <- total_rows / 2

# Open connections for reading and writing
input_file <- file("C:\\Users\\bobbt\\Downloads\\Medicare_Part_D_Prescribers_by_Provider_and_Drug_2022.csv", open = "r")
output_file <- file("C:\\Users\\bobbt\\Downloads\\Medicare_Part_D_Second_Half.csv", open = "w")

# Read and write the header to the second half file
header <- readLines(input_file, n = 1)
writeLines(header, output_file)

# Skip the first half of the rows
for (i in 2:split_point) {
  readLines(input_file, n = 1)  # Skip rows without saving them
}

# Write the second half of the rows to the new file
for (i in (split_point + 1):total_rows) {
  line <- readLines(input_file, n = 1)
  writeLines(line, output_file)
}

# Close connections
close(input_file)
close(output_file)

```


read medicare_part_d and leie dataset and uploiad it to 
```{r}
# Define the file path
file_path <- "C:\\Users\\bobbt\\Downloads\\medicare_part_2.csv"
leie_path <- "C:\\Users\\bobbt\\Downloads\\leie.csv"

# Read the CSV file
data <- fread(file_path)
datas <- fread(leie_path)

# Check the number of rows
num_rows <- nrow(data)
print(num_rows)

dbWriteTable(con, "medicare_part_2_data", as.data.frame(data), overwrite = TRUE, row.names = FALSE)
dbDisconnect(con)
```



```{r}
dbWriteTable(con, "medicare_part_2_data", as.data.frame(data), overwrite = TRUE, row.names = FALSE)
dbDisconnect(con)
dbWriteTable(con, "leie", as.data.frame(datas), overwrite = TRUE, row.names = FALSE)
```


```{r}
dbWriteTable(con, "leie", as.data.frame(datas), overwrite = TRUE, row.names = FALSE)

```
Import the data into data frames
```{r}
# Import medicare_part_b
medicare_part_b <- dbGetQuery(con, "SELECT * FROM medicare_part_b")

# Import medicare_part_d
medicare_part_d <- dbGetQuery(con, "SELECT * FROM medicare_part_d")

# Import dmepos
dmepos <- dbGetQuery(con, "SELECT * FROM dmepos")

# Import combined_dataset
combined_dataset <- dbGetQuery(con, "SELECT * FROM combined_dataset")
```

Replace NA values in exclusion column with 0
```{r}
medicare_part_b$Exclusion <- ifelse(is.na(medicare_part_b$Exclusion), 0, medicare_part_b$Exclusion)

medicare_part_d$Exclusion <- ifelse(is.na(medicare_part_d$Exclusion), 0, medicare_part_d$Exclusion)

dmepos$Exclusion <- ifelse(is.na(dmepos$Exclusion), 0, dmepos$Exclusion)

combined_dataset$Exclusion <- ifelse(is.na(combined_dataset$Exclusion), 0, combined_dataset$Exclusion)
```


Now lets call a function to calculate the percentage of fraudulent to non-fraudulent cases
```{r}
calc_fraud_stats <- function(dataset){
  total <- nrow(dataset)
  fraud <- sum(dataset$Exclusion == 1, na.rm = TRUE)
  non_fraud = total - fraud
  percent_fraud = (fraud/total) * 100
  return(c(Non_fraudulent = non_fraud,
           Fraudulent = fraud,
           Percent_Fraudulent= percent_fraud))
}

part_b_stats <- calc_fraud_stats(medicare_part_b)
part_d_stats <- calc_fraud_stats(medicare_part_d)
dmepos_stats <- calc_fraud_stats(dmepos)
combined_stats <- calc_fraud_stats(combined_dataset)

fraud_table <- data.frame(Dataset = c("Part B", "Part D", "DMEPOS", "Combined"),
  Non_fraudulent = c(part_b_stats["Non_fraudulent"], 
                     part_d_stats["Non_fraudulent"], 
                     dmepos_stats["Non_fraudulent"], 
                     combined_stats["Non_fraudulent"]),
  Fraudulent = c(part_b_stats["Fraudulent"], 
                 part_d_stats["Fraudulent"], 
                 dmepos_stats["Fraudulent"], 
                 combined_stats["Fraudulent"]),
  Percent_Fraudulent = c(part_b_stats["Percent_Fraudulent"], 
                         part_d_stats["Percent_Fraudulent"], 
                         dmepos_stats["Percent_Fraudulent"], 
                         combined_stats["Percent_Fraudulent"]))

fraud_table$Percent_Fraudulent <- round(fraud_table$Percent_Fraudulent, 3)
kable(fraud_table, format = "markdown", digits = 3)
```

So the DMEPOS has the highest percentage of Fraudulent data at 0.027% pf fraudulent data

Implement one-hot-encoding for gender and provider type for Dmepos dataset
```{r}

dmepos <- dmepos %>%
  mutate(
    gender_male = case_when(
      Referring_provider_gender == "M" ~ 1,
      Referring_provider_gender == "F" ~ 0,
      TRUE ~ 0  
    ),
    gender_female = case_when(
      Referring_provider_gender == "F" ~ 1,
      Referring_provider_gender == "M" ~ 0,
      TRUE ~ 0  
    )
  )

# One-hot encoding for provider type/specialty
provider_types <- unique(dmepos$Referring_provider_type)

# Create a one-hot encoded column for each provider type
for (type in provider_types) {
  col_name <- paste0("provider_type_", make.names(type))
  dmepos[[col_name]] <- as.integer(dmepos$Referring_provider_type == type)
}

# Remove original categorical columns and NPI
dmepos <- dmepos %>%
  select(-Referring_provider_gender, -Referring_provider_type, -Referring_npi)

```

Implement one-hot-encoding for gender and provider type for Medicare_part_B
```{r}

medicare_part_b <- medicare_part_b %>%
  mutate(
    gender_male = case_when(
      Nppes_provider_gender == "M" ~ 1,
      Nppes_provider_gender == "F" ~ 0,
      TRUE ~ 0  
    ),
    gender_female = case_when(
      Nppes_provider_gender == "F" ~ 1,
      Nppes_provider_gender == "M" ~ 0,
      TRUE ~ 0  
    )
  )

# One-hot encoding for provider type
provider_types <- unique(medicare_part_b$Provider_type)
for (type in provider_types) {
  col_name <- paste0("provider_type_", make.names(type))
  medicare_part_b[[col_name]] <- as.integer(medicare_part_b$Provider_type == type)
}

# Remove original categorical columns and NPI
medicare_part_b <- medicare_part_b %>%
  select(-Nppes_provider_gender, -Provider_type, -Npi)
```


Implement one-hot-encoding for gender and provider type for Medicare_part_D
```{r}

# One-hot encoding for specialty description
specialty_descriptions <- unique(medicare_part_d$Specialty_description)
for (desc in specialty_descriptions) {
  col_name <- paste0("specialty_", make.names(desc))
  medicare_part_d[[col_name]] <- as.integer(medicare_part_d$Specialty_description == desc)
}

# Remove original categorical column and NPI
medicare_part_d <- medicare_part_d %>%
  select(-Specialty_description, -Npi)
```


Implement one-hot-encoding for gender and provider type for Combined dataset
```{r}

# One-hot encoding for gender
combined_dataset <- combined_dataset %>%
  mutate(
    gender_male = case_when(
      Nppes_provider_gender == "M" ~ 1,
      Nppes_provider_gender == "F" ~ 0,
      TRUE ~ 0  
    ),
    gender_female = case_when(
      Nppes_provider_gender == "F" ~ 1,
      Nppes_provider_gender == "M" ~ 0,
      TRUE ~ 0  
    )
  )

# One-hot encoding for provider type
provider_types <- unique(combined_dataset$Provider_type)
for (type in provider_types) {
  col_name <- paste0("provider_type_", make.names(type))
  combined_dataset[[col_name]] <- as.integer(combined_dataset$Provider_type == type)
}

# Remove original categorical columns and NPI
combined_dataset <- combined_dataset %>%
  select(-Nppes_provider_gender, -Provider_type, -Npi)
```

### Binomial Logistic regression

#### DMEPOS
check for na values
```{r}
sum(is.na(dmepos))
```
No NA values, lets see the distribution of the numerical columns to check for any outliers
```{r}
library(ggplot2)

# Function to plot histograms for selected columns
plot_histograms <- function(df, columns) {
  for (col in columns) {
    # Create a ggplot object
    p <- ggplot(df, aes_string(x = col)) +
      geom_histogram(binwidth = 30, fill = "blue", color = "black", alpha = 0.7) +
      labs(title = paste("Histogram of", col), x = col, y = "Frequency") +
      theme_minimal()
    
    # Print the plot
    print(p)
  }
}

# Specify the columns you want to create histograms for, ommitting the beneficiary columns, it leads to highly skewed distributions
columns_to_plot <- c(
  "avg_number_of_suppliers", 
  "sum_number_of_suppliers", 
  "stddev_number_of_suppliers",
  "min_number_of_suppliers", 
  "max_number_of_suppliers",
  "avg_number_of_supplier_claims",
  "sum_number_of_supplier_claims",
  "stddev_number_of_supplier_claims",
  "min_number_of_supplier_claims",
  "max_number_of_supplier_claims",
  "avg_number_of_supplier_services",
  "sum_number_of_supplier_services",
  "stddev_number_of_supplier_services",
  "min_number_of_supplier_services",
  "max_number_of_supplier_services",
  "avg_supplier_submitted_charge",
  "stddev_supplier_submitted_charge",
  "min_supplier_submitted_charge",
  "max_supplier_submitted_charge",
  "avg_supplier_medicare_payment",
  "stddev_supplier_medicare_payment",
  "min_supplier_medicare_payment",
  "max_supplier_medicare_payment"
)

plot_histograms(dmepos, columns_to_plot)

```


There are some outliers, a rule of thumb is to look out for values that are 1.5 times the iqr above the 75th ir te 25th percentile
```{r}
find_outliers_iqr <- function(df, column) {
  Q1 <- quantile(df[[column]], 0.25, na.rm = TRUE)
  Q3 <- quantile(df[[column]], 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
  outliers <- df[[column]][df[[column]] < lower_bound | df[[column]] > upper_bound]
  return(outliers)
}

```

Im going to go through every numerical column specifieied, and call trhe find_outliers_iqr function so that every row that contains the outlier is dropped
```{r}
remove_outliers <- function(df, column) {
  outliers <- find_outliers_iqr(df, column)
  df <- df[!(df[[column]] %in% outliers), ]
  return(df)
}

# Main loop to process all columns
for (column in columns_to_plot) {
  tryCatch({
    print(paste("Processing column:", column))
    dmepos <- remove_outliers(dmepos, column)
    print(paste("Rows remaining after processing", column, ":", nrow(dmepos)))
  }, error = function(e) {
    print(paste("Error processing column:", column))
    print(e)
  })
}
```

puting back benficiary coluymns to see the distirbution as well
```{r}
columns_to_plot <- c(
  "avg_number_of_suppliers", 
  "sum_number_of_suppliers", 
  "stddev_number_of_suppliers",
  "min_number_of_suppliers", 
  "max_number_of_suppliers",
  "max_number_of_supplier_beneficiaries", 
  "avg_number_of_supplier_beneficiaries",
  "sum_number_of_supplier_beneficiaries", 
  "stddev_number_of_supplier_beneficiaries",
  "min_number_of_supplier_beneficiaries",
  "avg_number_of_supplier_claims",
  "sum_number_of_supplier_claims",
  "stddev_number_of_supplier_claims",
  "min_number_of_supplier_claims",
  "max_number_of_supplier_claims",
  "avg_number_of_supplier_services",
  "sum_number_of_supplier_services",
  "stddev_number_of_supplier_services",
  "min_number_of_supplier_services",
  "max_number_of_supplier_services",
  "avg_supplier_submitted_charge",
  "stddev_supplier_submitted_charge",
  "min_supplier_submitted_charge",
  "max_supplier_submitted_charge",
  "avg_supplier_medicare_payment",
  "stddev_supplier_medicare_payment",
  "min_supplier_medicare_payment",
  "max_supplier_medicare_payment"
)
```

Distribution after removing outliers


```{r}
generate_histograms_for_columns <- function(data, columns, output_dir = NULL, log_scale = FALSE) {
  # Create output directory if specified
  if (!is.null(output_dir)) {
    dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
  }
  
  # List to store all plots
  plot_list <- list()
  
  for (column in columns) {
    tryCatch({
      print(paste("Processing column:", column))
      
      # Generate the plot
      plot <- generate_improved_histogram(data, column, log_scale = log_scale)
      
      # Add the plot to the list
      plot_list[[column]] <- plot
      
      # Save the plot if output directory is specified
      if (!is.null(output_dir)) {
        ggsave(filename = file.path(output_dir, paste0(column, ".png")), 
               plot = plot, width = 10, height = 6)
      }
      
      # Print the plot
      print(plot)
      
    }, error = function(e) {
      warning(paste("Error processing column:", column, "\nError message:", e$message))
    })
  }
  
  # Return the list of plots
  return(plot_list)
}

 all_plots <- generate_histograms_for_columns(dmepos, columns_to_plot, output_dir = "histogram_plots")
```

The distribution looks much better now, T

